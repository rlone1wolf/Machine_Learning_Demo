{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM——Otto商品分类\n",
    "\n",
    "我们以Kaggle 2015年举办的Otto Group Product Classification Challenge竞赛数据为例，SVC、SVC + GridSearchCV进行参数调优。\n",
    "\n",
    "Otto数据集是著名电商Otto提供的一个多类商品分类问题，类别数=9. 每个样本有93维数值型特征（整数，表示某种事件发生的次数，已经进行过脱敏处理）。 竞赛官网：https://www.kaggle.com/c/otto-group-product-classification-challenge/data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T11:54:03.773000Z",
     "start_time": "2018-02-02T11:54:02.234000Z"
    }
   },
   "outputs": [],
   "source": [
    "# 首先 import 必要的模块\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#竞赛的评价指标为logloss\n",
    "#from sklearn.metrics import log_loss  \n",
    "#SVM并不能直接输出各类的概率，所以在这个例子中我们用正确率作为模型预测性能的度量\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from zhou.utils_zhou import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据 & 数据探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T11:54:21.039000Z",
     "start_time": "2018-02-02T11:54:19.961000Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_85</th>\n",
       "      <th>feat_86</th>\n",
       "      <th>feat_87</th>\n",
       "      <th>feat_88</th>\n",
       "      <th>feat_89</th>\n",
       "      <th>feat_90</th>\n",
       "      <th>feat_91</th>\n",
       "      <th>feat_92</th>\n",
       "      <th>feat_93</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  feat_8  feat_9  \\\n",
       "0   1       1       0       0       0       0       0       0       0       0   \n",
       "1   2       0       0       0       0       0       0       0       1       0   \n",
       "2   3       0       0       0       0       0       0       0       1       0   \n",
       "3   4       1       0       0       1       6       1       5       0       0   \n",
       "4   5       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "    ...     feat_85  feat_86  feat_87  feat_88  feat_89  feat_90  feat_91  \\\n",
       "0   ...           1        0        0        0        0        0        0   \n",
       "1   ...           0        0        0        0        0        0        0   \n",
       "2   ...           0        0        0        0        0        0        0   \n",
       "3   ...           0        1        2        0        0        0        0   \n",
       "4   ...           1        0        0        0        0        1        0   \n",
       "\n",
       "   feat_92  feat_93   target  \n",
       "0        0        0  Class_1  \n",
       "1        0        0  Class_1  \n",
       "2        0        0  Class_1  \n",
       "3        0        0  Class_1  \n",
       "4        0        0  Class_1  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取数据\n",
    "# path to where the data lies\n",
    "dpath = './data/'\n",
    "train = pd.read_csv(dpath +\"Otto_train.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T11:54:22.770000Z",
     "start_time": "2018-02-02T11:54:22.764000Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共有：[61878]条样本，特征数为：[95]，其中有[94]个特征是number\n",
      "使用内存大小为: [44.38] KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>dif_vals</th>\n",
       "      <th>dtype</th>\n",
       "      <th>num_null</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>61878</td>\n",
       "      <td>30939.500000</td>\n",
       "      <td>17862.784315</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15470.25</td>\n",
       "      <td>30939.5</td>\n",
       "      <td>46408.75</td>\n",
       "      <td>61878.0</td>\n",
       "      <td>61878</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_1</th>\n",
       "      <td>61878</td>\n",
       "      <td>0.386680</td>\n",
       "      <td>1.525330</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>61.0</td>\n",
       "      <td>42</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_2</th>\n",
       "      <td>61878</td>\n",
       "      <td>0.263066</td>\n",
       "      <td>1.252073</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>51.0</td>\n",
       "      <td>37</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_3</th>\n",
       "      <td>61878</td>\n",
       "      <td>0.901467</td>\n",
       "      <td>2.934818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>64.0</td>\n",
       "      <td>48</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_4</th>\n",
       "      <td>61878</td>\n",
       "      <td>0.779081</td>\n",
       "      <td>2.788005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>70.0</td>\n",
       "      <td>59</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_5</th>\n",
       "      <td>61878</td>\n",
       "      <td>0.071043</td>\n",
       "      <td>0.438902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19.0</td>\n",
       "      <td>15</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_6</th>\n",
       "      <td>61878</td>\n",
       "      <td>0.025696</td>\n",
       "      <td>0.215333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_7</th>\n",
       "      <td>61878</td>\n",
       "      <td>0.193704</td>\n",
       "      <td>1.030102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_8</th>\n",
       "      <td>61878</td>\n",
       "      <td>0.662433</td>\n",
       "      <td>2.255770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>76.0</td>\n",
       "      <td>55</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_9</th>\n",
       "      <td>61878</td>\n",
       "      <td>1.011296</td>\n",
       "      <td>3.474822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>43.0</td>\n",
       "      <td>40</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_10</th>\n",
       "      <td>61878</td>\n",
       "      <td>0.263906</td>\n",
       "      <td>1.083340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>30.0</td>\n",
       "      <td>26</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_11</th>\n",
       "      <td>61878</td>\n",
       "      <td>1.252869</td>\n",
       "      <td>3.042333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>38.0</td>\n",
       "      <td>28</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_12</th>\n",
       "      <td>61878</td>\n",
       "      <td>0.140874</td>\n",
       "      <td>0.567089</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>30.0</td>\n",
       "      <td>20</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_13</th>\n",
       "      <td>61878</td>\n",
       "      <td>0.480979</td>\n",
       "      <td>2.014697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>72.0</td>\n",
       "      <td>51</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_14</th>\n",
       "      <td>61878</td>\n",
       "      <td>1.696693</td>\n",
       "      <td>3.163212</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>33.0</td>\n",
       "      <td>32</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_15</th>\n",
       "      <td>61878</td>\n",
       "      <td>1.284398</td>\n",
       "      <td>3.862236</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>46.0</td>\n",
       "      <td>37</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_16</th>\n",
       "      <td>61878</td>\n",
       "      <td>1.413459</td>\n",
       "      <td>2.226163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>37.0</td>\n",
       "      <td>28</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_17</th>\n",
       "      <td>61878</td>\n",
       "      <td>0.366108</td>\n",
       "      <td>1.477436</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>43.0</td>\n",
       "      <td>40</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_18</th>\n",
       "      <td>61878</td>\n",
       "      <td>0.575423</td>\n",
       "      <td>1.335985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>32.0</td>\n",
       "      <td>30</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_19</th>\n",
       "      <td>61878</td>\n",
       "      <td>0.551699</td>\n",
       "      <td>4.636145</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>121.0</td>\n",
       "      <td>105</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_20</th>\n",
       "      <td>61878</td>\n",
       "      <td>0.471525</td>\n",
       "      <td>1.438727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_21</th>\n",
       "      <td>61878</td>\n",
       "      <td>0.204014</td>\n",
       "      <td>0.696050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_22</th>\n",
       "      <td>61878</td>\n",
       "      <td>0.729969</td>\n",
       "      <td>1.446220</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_23</th>\n",
       "      <td>61878</td>\n",
       "      <td>0.142522</td>\n",
       "      <td>0.782979</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>64.0</td>\n",
       "      <td>24</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_24</th>\n",
       "      <td>61878</td>\n",
       "      <td>2.643880</td>\n",
       "      <td>4.629015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>263.0</td>\n",
       "      <td>66</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_25</th>\n",
       "      <td>61878</td>\n",
       "      <td>1.534520</td>\n",
       "      <td>2.332994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>30.0</td>\n",
       "      <td>28</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_26</th>\n",
       "      <td>61878</td>\n",
       "      <td>0.563108</td>\n",
       "      <td>1.710305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33.0</td>\n",
       "      <td>31</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_27</th>\n",
       "      <td>61878</td>\n",
       "      <td>0.696613</td>\n",
       "      <td>2.873222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>123.0</td>\n",
       "      <td>55</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_28</th>\n",
       "      <td>61878</td>\n",
       "      <td>0.238970</td>\n",
       "      <td>0.828112</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_29</th>\n",
       "      <td>61878</td>\n",
       "      <td>0.275768</td>\n",
       "      <td>1.901294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>69.0</td>\n",
       "      <td>50</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_64</th>\n",
       "      <td>61878</td>\n",
       "      <td>1.256796</td>\n",
       "      <td>3.402080</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>73.0</td>\n",
       "      <td>49</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_65</th>\n",
       "      <td>61878</td>\n",
       "      <td>0.222228</td>\n",
       "      <td>0.783052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>38.0</td>\n",
       "      <td>25</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_66</th>\n",
       "      <td>61878</td>\n",
       "      <td>0.571706</td>\n",
       "      <td>1.361874</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>36.0</td>\n",
       "      <td>34</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_67</th>\n",
       "      <td>61878</td>\n",
       "      <td>2.897653</td>\n",
       "      <td>4.974322</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>104.0</td>\n",
       "      <td>72</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_68</th>\n",
       "      <td>61878</td>\n",
       "      <td>0.392902</td>\n",
       "      <td>1.761054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>109.0</td>\n",
       "      <td>39</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_69</th>\n",
       "      <td>61878</td>\n",
       "      <td>0.811128</td>\n",
       "      <td>4.111091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>76.0</td>\n",
       "      <td>65</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_70</th>\n",
       "      <td>61878</td>\n",
       "      <td>0.892789</td>\n",
       "      <td>1.941368</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>46.0</td>\n",
       "      <td>35</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_71</th>\n",
       "      <td>61878</td>\n",
       "      <td>0.319290</td>\n",
       "      <td>1.162443</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>31.0</td>\n",
       "      <td>28</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_72</th>\n",
       "      <td>61878</td>\n",
       "      <td>0.858722</td>\n",
       "      <td>2.411646</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>30.0</td>\n",
       "      <td>31</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_73</th>\n",
       "      <td>61878</td>\n",
       "      <td>0.591050</td>\n",
       "      <td>5.783233</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>352.0</td>\n",
       "      <td>115</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_74</th>\n",
       "      <td>61878</td>\n",
       "      <td>0.579851</td>\n",
       "      <td>3.757822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>231.0</td>\n",
       "      <td>101</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_75</th>\n",
       "      <td>61878</td>\n",
       "      <td>0.726817</td>\n",
       "      <td>3.200095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>80.0</td>\n",
       "      <td>70</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_76</th>\n",
       "      <td>61878</td>\n",
       "      <td>0.748457</td>\n",
       "      <td>2.920038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>102.0</td>\n",
       "      <td>61</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_77</th>\n",
       "      <td>61878</td>\n",
       "      <td>0.124196</td>\n",
       "      <td>0.906621</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.0</td>\n",
       "      <td>24</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_78</th>\n",
       "      <td>61878</td>\n",
       "      <td>0.366415</td>\n",
       "      <td>2.778317</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>80.0</td>\n",
       "      <td>70</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_79</th>\n",
       "      <td>61878</td>\n",
       "      <td>0.300446</td>\n",
       "      <td>1.285569</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.0</td>\n",
       "      <td>22</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_80</th>\n",
       "      <td>61878</td>\n",
       "      <td>0.698067</td>\n",
       "      <td>2.245671</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>54.0</td>\n",
       "      <td>41</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_81</th>\n",
       "      <td>61878</td>\n",
       "      <td>0.078461</td>\n",
       "      <td>0.461244</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>26.0</td>\n",
       "      <td>19</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_82</th>\n",
       "      <td>61878</td>\n",
       "      <td>0.187983</td>\n",
       "      <td>0.836269</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24.0</td>\n",
       "      <td>23</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_83</th>\n",
       "      <td>61878</td>\n",
       "      <td>0.496719</td>\n",
       "      <td>2.434921</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>79.0</td>\n",
       "      <td>57</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_84</th>\n",
       "      <td>61878</td>\n",
       "      <td>0.070752</td>\n",
       "      <td>1.151460</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>76.0</td>\n",
       "      <td>42</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_85</th>\n",
       "      <td>61878</td>\n",
       "      <td>0.532306</td>\n",
       "      <td>1.900438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>55.0</td>\n",
       "      <td>42</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_86</th>\n",
       "      <td>61878</td>\n",
       "      <td>1.128576</td>\n",
       "      <td>2.681554</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>65.0</td>\n",
       "      <td>52</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_87</th>\n",
       "      <td>61878</td>\n",
       "      <td>0.393549</td>\n",
       "      <td>1.575455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>67.0</td>\n",
       "      <td>49</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_88</th>\n",
       "      <td>61878</td>\n",
       "      <td>0.874915</td>\n",
       "      <td>2.115466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>30.0</td>\n",
       "      <td>31</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_89</th>\n",
       "      <td>61878</td>\n",
       "      <td>0.457772</td>\n",
       "      <td>1.527385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>61.0</td>\n",
       "      <td>37</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_90</th>\n",
       "      <td>61878</td>\n",
       "      <td>0.812421</td>\n",
       "      <td>4.597804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>130.0</td>\n",
       "      <td>91</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_91</th>\n",
       "      <td>61878</td>\n",
       "      <td>0.264941</td>\n",
       "      <td>2.045646</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>52.0</td>\n",
       "      <td>50</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_92</th>\n",
       "      <td>61878</td>\n",
       "      <td>0.380119</td>\n",
       "      <td>0.982385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_93</th>\n",
       "      <td>61878</td>\n",
       "      <td>0.126135</td>\n",
       "      <td>1.201720</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>87.0</td>\n",
       "      <td>43</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         count          mean           std  min       25%      50%       75%  \\\n",
       "id       61878  30939.500000  17862.784315  1.0  15470.25  30939.5  46408.75   \n",
       "feat_1   61878      0.386680      1.525330  0.0      0.00      0.0      0.00   \n",
       "feat_2   61878      0.263066      1.252073  0.0      0.00      0.0      0.00   \n",
       "feat_3   61878      0.901467      2.934818  0.0      0.00      0.0      0.00   \n",
       "feat_4   61878      0.779081      2.788005  0.0      0.00      0.0      0.00   \n",
       "feat_5   61878      0.071043      0.438902  0.0      0.00      0.0      0.00   \n",
       "feat_6   61878      0.025696      0.215333  0.0      0.00      0.0      0.00   \n",
       "feat_7   61878      0.193704      1.030102  0.0      0.00      0.0      0.00   \n",
       "feat_8   61878      0.662433      2.255770  0.0      0.00      0.0      1.00   \n",
       "feat_9   61878      1.011296      3.474822  0.0      0.00      0.0      0.00   \n",
       "feat_10  61878      0.263906      1.083340  0.0      0.00      0.0      0.00   \n",
       "feat_11  61878      1.252869      3.042333  0.0      0.00      0.0      1.00   \n",
       "feat_12  61878      0.140874      0.567089  0.0      0.00      0.0      0.00   \n",
       "feat_13  61878      0.480979      2.014697  0.0      0.00      0.0      0.00   \n",
       "feat_14  61878      1.696693      3.163212  0.0      0.00      0.0      2.00   \n",
       "feat_15  61878      1.284398      3.862236  0.0      0.00      0.0      1.00   \n",
       "feat_16  61878      1.413459      2.226163  0.0      0.00      0.0      2.00   \n",
       "feat_17  61878      0.366108      1.477436  0.0      0.00      0.0      0.00   \n",
       "feat_18  61878      0.575423      1.335985  0.0      0.00      0.0      1.00   \n",
       "feat_19  61878      0.551699      4.636145  0.0      0.00      0.0      0.00   \n",
       "feat_20  61878      0.471525      1.438727  0.0      0.00      0.0      0.00   \n",
       "feat_21  61878      0.204014      0.696050  0.0      0.00      0.0      0.00   \n",
       "feat_22  61878      0.729969      1.446220  0.0      0.00      0.0      1.00   \n",
       "feat_23  61878      0.142522      0.782979  0.0      0.00      0.0      0.00   \n",
       "feat_24  61878      2.643880      4.629015  0.0      0.00      1.0      3.00   \n",
       "feat_25  61878      1.534520      2.332994  0.0      0.00      1.0      2.00   \n",
       "feat_26  61878      0.563108      1.710305  0.0      0.00      0.0      0.00   \n",
       "feat_27  61878      0.696613      2.873222  0.0      0.00      0.0      0.00   \n",
       "feat_28  61878      0.238970      0.828112  0.0      0.00      0.0      0.00   \n",
       "feat_29  61878      0.275768      1.901294  0.0      0.00      0.0      0.00   \n",
       "...        ...           ...           ...  ...       ...      ...       ...   \n",
       "feat_64  61878      1.256796      3.402080  0.0      0.00      0.0      1.00   \n",
       "feat_65  61878      0.222228      0.783052  0.0      0.00      0.0      0.00   \n",
       "feat_66  61878      0.571706      1.361874  0.0      0.00      0.0      1.00   \n",
       "feat_67  61878      2.897653      4.974322  0.0      0.00      1.0      4.00   \n",
       "feat_68  61878      0.392902      1.761054  0.0      0.00      0.0      0.00   \n",
       "feat_69  61878      0.811128      4.111091  0.0      0.00      0.0      0.00   \n",
       "feat_70  61878      0.892789      1.941368  0.0      0.00      0.0      1.00   \n",
       "feat_71  61878      0.319290      1.162443  0.0      0.00      0.0      0.00   \n",
       "feat_72  61878      0.858722      2.411646  0.0      0.00      0.0      1.00   \n",
       "feat_73  61878      0.591050      5.783233  0.0      0.00      0.0      0.00   \n",
       "feat_74  61878      0.579851      3.757822  0.0      0.00      0.0      0.00   \n",
       "feat_75  61878      0.726817      3.200095  0.0      0.00      0.0      0.00   \n",
       "feat_76  61878      0.748457      2.920038  0.0      0.00      0.0      0.00   \n",
       "feat_77  61878      0.124196      0.906621  0.0      0.00      0.0      0.00   \n",
       "feat_78  61878      0.366415      2.778317  0.0      0.00      0.0      0.00   \n",
       "feat_79  61878      0.300446      1.285569  0.0      0.00      0.0      0.00   \n",
       "feat_80  61878      0.698067      2.245671  0.0      0.00      0.0      0.00   \n",
       "feat_81  61878      0.078461      0.461244  0.0      0.00      0.0      0.00   \n",
       "feat_82  61878      0.187983      0.836269  0.0      0.00      0.0      0.00   \n",
       "feat_83  61878      0.496719      2.434921  0.0      0.00      0.0      0.00   \n",
       "feat_84  61878      0.070752      1.151460  0.0      0.00      0.0      0.00   \n",
       "feat_85  61878      0.532306      1.900438  0.0      0.00      0.0      0.00   \n",
       "feat_86  61878      1.128576      2.681554  0.0      0.00      0.0      1.00   \n",
       "feat_87  61878      0.393549      1.575455  0.0      0.00      0.0      0.00   \n",
       "feat_88  61878      0.874915      2.115466  0.0      0.00      0.0      1.00   \n",
       "feat_89  61878      0.457772      1.527385  0.0      0.00      0.0      0.00   \n",
       "feat_90  61878      0.812421      4.597804  0.0      0.00      0.0      0.00   \n",
       "feat_91  61878      0.264941      2.045646  0.0      0.00      0.0      0.00   \n",
       "feat_92  61878      0.380119      0.982385  0.0      0.00      0.0      0.00   \n",
       "feat_93  61878      0.126135      1.201720  0.0      0.00      0.0      0.00   \n",
       "\n",
       "             max  dif_vals  dtype  num_null  \n",
       "id       61878.0     61878  int64         0  \n",
       "feat_1      61.0        42  int64         0  \n",
       "feat_2      51.0        37  int64         0  \n",
       "feat_3      64.0        48  int64         0  \n",
       "feat_4      70.0        59  int64         0  \n",
       "feat_5      19.0        15  int64         0  \n",
       "feat_6      10.0         9  int64         0  \n",
       "feat_7      38.0        30  int64         0  \n",
       "feat_8      76.0        55  int64         0  \n",
       "feat_9      43.0        40  int64         0  \n",
       "feat_10     30.0        26  int64         0  \n",
       "feat_11     38.0        28  int64         0  \n",
       "feat_12     30.0        20  int64         0  \n",
       "feat_13     72.0        51  int64         0  \n",
       "feat_14     33.0        32  int64         0  \n",
       "feat_15     46.0        37  int64         0  \n",
       "feat_16     37.0        28  int64         0  \n",
       "feat_17     43.0        40  int64         0  \n",
       "feat_18     32.0        30  int64         0  \n",
       "feat_19    121.0       105  int64         0  \n",
       "feat_20     27.0        27  int64         0  \n",
       "feat_21     14.0        15  int64         0  \n",
       "feat_22     22.0        21  int64         0  \n",
       "feat_23     64.0        24  int64         0  \n",
       "feat_24    263.0        66  int64         0  \n",
       "feat_25     30.0        28  int64         0  \n",
       "feat_26     33.0        31  int64         0  \n",
       "feat_27    123.0        55  int64         0  \n",
       "feat_28     22.0        21  int64         0  \n",
       "feat_29     69.0        50  int64         0  \n",
       "...          ...       ...    ...       ...  \n",
       "feat_64     73.0        49  int64         0  \n",
       "feat_65     38.0        25  int64         0  \n",
       "feat_66     36.0        34  int64         0  \n",
       "feat_67    104.0        72  int64         0  \n",
       "feat_68    109.0        39  int64         0  \n",
       "feat_69     76.0        65  int64         0  \n",
       "feat_70     46.0        35  int64         0  \n",
       "feat_71     31.0        28  int64         0  \n",
       "feat_72     30.0        31  int64         0  \n",
       "feat_73    352.0       115  int64         0  \n",
       "feat_74    231.0       101  int64         0  \n",
       "feat_75     80.0        70  int64         0  \n",
       "feat_76    102.0        61  int64         0  \n",
       "feat_77     29.0        24  int64         0  \n",
       "feat_78     80.0        70  int64         0  \n",
       "feat_79     25.0        22  int64         0  \n",
       "feat_80     54.0        41  int64         0  \n",
       "feat_81     26.0        19  int64         0  \n",
       "feat_82     24.0        23  int64         0  \n",
       "feat_83     79.0        57  int64         0  \n",
       "feat_84     76.0        42  int64         0  \n",
       "feat_85     55.0        42  int64         0  \n",
       "feat_86     65.0        52  int64         0  \n",
       "feat_87     67.0        49  int64         0  \n",
       "feat_88     30.0        31  int64         0  \n",
       "feat_89     61.0        37  int64         0  \n",
       "feat_90    130.0        91  int64         0  \n",
       "feat_91     52.0        50  int64         0  \n",
       "feat_92     19.0        19  int64         0  \n",
       "feat_93     87.0        43  int64         0  \n",
       "\n",
       "[94 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_number_describe(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T11:54:24.484000Z",
     "start_time": "2018-02-02T11:54:23.906000Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共有：[61878]条样本，特征数为：[95]，其中有[1]个特征是object\n",
      "使用内存大小为: [483.5] KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>dif_vals</th>\n",
       "      <th>dtype</th>\n",
       "      <th>num_null</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>61878</td>\n",
       "      <td>9</td>\n",
       "      <td>Class_2</td>\n",
       "      <td>16122</td>\n",
       "      <td>9</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count unique      top   freq  dif_vals   dtype  num_null\n",
       "target  61878      9  Class_2  16122         9  object         0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 各属性的统计特性\n",
    "show_object_describe(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T11:54:25.059000Z",
     "start_time": "2018-02-02T11:54:24.734000Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Number of occurrences')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Target 分布，看看各类样本分布是否均衡\n",
    "sns.countplot(train.target)\n",
    "plt.xlabel('target')\n",
    "plt.xticks(rotation=-45)\n",
    "plt.ylabel('Number of occurrences')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各类样本不均衡。交叉验证对分类任务缺省的是采用StratifiedKFold，在每折采样时根据各类样本按比例采样"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T11:54:28.901000Z",
     "start_time": "2018-02-02T11:54:28.740000Z"
    }
   },
   "outputs": [],
   "source": [
    "# 将类别字符串变成数字\n",
    "# drop ids and get labels\n",
    "y_train = train['target']   #形式为Class_x\n",
    "y_train = y_train.map(lambda s: int(s[-1])-1)\n",
    "\n",
    "X_train = train.drop([\"id\", \"target\"], axis=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T11:54:32.498000Z",
     "start_time": "2018-02-02T11:54:32.241000Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhou/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/zhou/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# 数据标准化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 初始化特征的标准化器\n",
    "ss_X = StandardScaler()\n",
    "\n",
    "# 分别对训练和测试数据的特征进行标准化处理\n",
    "X_train = ss_X.fit_transform(X_train)\n",
    "#X_test = ss_X.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T11:54:33.796000Z",
     "start_time": "2018-02-02T11:54:33.651000Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhou/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# 训练样本6w+，交叉验证太慢，用train_test_split估计模型性能\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_part, X_val, y_train_part, y_val = train_test_split(X_train, y_train, train_size = 0.8,random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### default SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T11:57:31.631000Z",
     "start_time": "2018-02-02T11:54:37.029000Z"
    }
   },
   "outputs": [],
   "source": [
    "#LinearSVC不能得到每类的概率，在Otto数据集要求输出每类的概率，这里只是示意SVM的使用方法\n",
    "#https://xacecask2.gitbooks.io/scikit-learn-user-guide-chinese-version/content/sec1.4.html\n",
    "#1.4.1.2. 得分与概率\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "SVC1 = LinearSVC().fit(X_train_part, y_train_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T12:00:33.077000Z",
     "start_time": "2018-02-02T12:00:32.879000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.21      0.32       370\n",
      "          1       0.61      0.90      0.72      3205\n",
      "          2       0.52      0.25      0.34      1546\n",
      "          3       0.80      0.12      0.21       566\n",
      "          4       0.96      0.94      0.95       542\n",
      "          5       0.91      0.93      0.92      2823\n",
      "          6       0.72      0.53      0.61       572\n",
      "          7       0.85      0.90      0.88      1703\n",
      "          8       0.85      0.83      0.84      1049\n",
      "\n",
      "avg / total       0.75      0.75      0.72     12376\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[  78   51    1    0    1   43    9   89   98]\n",
      " [   1 2886  265    6    8   12   16    9    2]\n",
      " [   0 1100  394    4    2    4   32    7    3]\n",
      " [   0  395   53   70    4   35    8    1    0]\n",
      " [   0   30    1    0  510    0    0    1    0]\n",
      " [  10   62    4    4    1 2614   31   60   37]\n",
      " [   8  129   28    1    2   57  304   41    2]\n",
      " [  16   51    5    0    3   58   13 1540   17]\n",
      " [   7   56    1    2    1   44    8   55  875]]\n"
     ]
    }
   ],
   "source": [
    "#在校验集上测试，估计模型性能\n",
    "from sklearn import metrics\n",
    "y_predict = SVC1.predict(X_val)\n",
    "\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (SVC1, metrics.classification_report(y_val, y_predict)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(y_val, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 线性SVM正则参数调优"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "线性SVM LinearSVC的需要调整正则超参数包括C（正则系数，一般在log域（取log后的值）均匀设置候选参数）和正则函数penalty（L2/L1） \n",
    "\n",
    "采用交叉验证，网格搜索步骤与Logistic回归正则参数处理类似，在此略。\n",
    "\n",
    "这里我们用校验集（X_val、y_val）来估计模型性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_grid_point_Linear(C, X_train, y_train, X_val, y_val):\n",
    "    \n",
    "    # 在训练集是那个利用SVC训练\n",
    "    SVC2 =  LinearSVC( C = C)\n",
    "    SVC2 = SVC2.fit(X_train, y_train)\n",
    "    \n",
    "    # 在校验集上返回accuracy\n",
    "    accuracy = SVC2.score(X_val, y_val)\n",
    "    \n",
    "    print(\"accuracy: {}\".format(accuracy))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7377989657401423\n",
      "accuracy: 0.7458791208791209\n",
      "accuracy: 0.7478991596638656\n",
      "accuracy: 0.7493535875888817\n",
      "accuracy: 0.7463639301874596\n",
      "accuracy: 0.677682611506141\n",
      "accuracy: 0.6101325145442793\n"
     ]
    }
   ],
   "source": [
    "#需要调优的参数\n",
    "C_s = np.logspace(-3, 3, 7)# logspace(a,b,N)把10的a次方到10的b次方区间分成N份  \n",
    "#penalty_s = ['l1','l2']\n",
    "\n",
    "accuracy_s = []\n",
    "for i, oneC in enumerate(C_s):\n",
    "#    for j, penalty in enumerate(penalty_s):\n",
    "    tmp = fit_grid_point_Linear(oneC, X_train, y_train, X_val, y_val)\n",
    "    accuracy_s.append(tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_axis = np.log10(C_s)\n",
    "#for j, penalty in enumerate(penalty_s):\n",
    "plt.plot(x_axis, np.array(accuracy_s), 'b-', label='l2')\n",
    "    \n",
    "plt.xlabel( 'log(C)' )                                                                                                      \n",
    "plt.ylabel( 'accuracy' )\n",
    "plt.legend()\n",
    "#plt.savefig('SVM_Otto.png' )\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RBF核SVM正则参数调优\n",
    "\n",
    "RBF核是SVM最常用的核函数。\n",
    "RBF核SVM 的需要调整正则超参数包括C（正则系数，一般在log域（取log后的值）均匀设置候选参数）和核函数的宽度gamma\n",
    "C越小，决策边界越平滑； \n",
    "gamma越小，决策边界越平滑。\n",
    "\n",
    "采用交叉验证，网格搜索步骤与Logistic回归正则参数处理类似，在此略。\n",
    "\n",
    "这里我们用校验集（X_val、y_val）来估计模型性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_grid_point_RBF(C, gamma, X_train, y_train, X_val, y_val):\n",
    "    \n",
    "    # 在训练集是那个利用SVC训练\n",
    "    SVC3 =  SVC( C = C, kernel='rbf', gamma = gamma)\n",
    "    SVC3 = SVC3.fit(X_train, y_train)\n",
    "    \n",
    "    # 在校验集上返回accuracy\n",
    "    accuracy = SVC3.score(X_val, y_val)\n",
    "    \n",
    "    print(\"accuracy: {0}\".format(accuracy))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6769553975436329\n",
      "accuracy: 0.4462669683257919\n",
      "accuracy: 0.2633322559793148\n"
     ]
    }
   ],
   "source": [
    "#需要调优的参数\n",
    "C_s = np.logspace(-2, 2, 5)# logspace(a,b,N)把10的a次方到10的b次方区间分成N份 \n",
    "gamma_s = np.logspace(-2, 2, 5)  \n",
    "\n",
    "accuracy_s = []\n",
    "for i, oneC in enumerate(C_s):\n",
    "    for j, gamma in enumerate(gamma_s):\n",
    "        tmp = fit_grid_point_RBF(oneC, gamma, X_train, y_train, X_val, y_val)\n",
    "        accuracy_s.append(tmp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上述部分运行结果来看，gamma参数设置不合适（gamma越大，对应RBF核的sigma越小，决策边界更复杂，可能发生了过拟合）\n",
    "所以调小gamma值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#需要调优的参数\n",
    "C_s = np.logspace(-1, 2, 4)# logspace(a,b,N)把10的a次方到10的b次方区间分成N份 \n",
    "gamma_s = np.logspace(-5, -2, 4)  \n",
    "\n",
    "accuracy_s = []\n",
    "for i, oneC in enumerate(C_s):\n",
    "    for j, gamma in enumerate(gamma_s):\n",
    "        tmp = fit_grid_point_RBF(oneC, gamma, X_train, y_train, X_val, y_val)\n",
    "        accuracy_s.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_s1 =np.array(accuracy_s).reshape(len(C_s),len(gamma_s))\n",
    "x_axis = np.log10(C_s)\n",
    "for j, gamma in enumerate(gamma_s):\n",
    "    plt.plot(x_axis, np.array(accuracy_s1[:,j]), label = ' Test - log(gamma)' + str(np.log10(gamma)))\n",
    "\n",
    "\n",
    "plt.xlabel( 'log(C)' )                                                                                                      \n",
    "plt.ylabel( 'accuracy' )\n",
    "plt.legend()\n",
    "#plt.savefig('RBF_SVM_Otto.png' )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
